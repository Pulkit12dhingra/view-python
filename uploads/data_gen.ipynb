{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bb94438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "rng = np.random.default_rng(seed=42)  # reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd4869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Helper functions\n",
    "# -----------------------------\n",
    "def random_datetimes(n, start, end, rng):\n",
    "    \"\"\"Generate n random datetimes between start and end (inclusive).\"\"\"\n",
    "    start_ts = pd.Timestamp(start).value // 10**9\n",
    "    end_ts = pd.Timestamp(end).value // 10**9\n",
    "    ts = rng.integers(low=start_ts, high=end_ts + 1, size=n, endpoint=True)\n",
    "    return pd.to_datetime(ts, unit=\"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd1b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Table 5: dim_product (4 rows, labels)\n",
    "# -----------------------------\n",
    "product_categories = [\n",
    "    (\"Electronics\", \"ACME\"),\n",
    "    (\"Furniture\", \"HomeCraft\"),\n",
    "    (\"Clothing\", \"UrbanWear\"),\n",
    "    (\"Grocery\", \"FreshFields\"),\n",
    "]\n",
    "dim_product = pd.DataFrame(\n",
    "    {\n",
    "        \"product_id\": np.arange(1, 5, dtype=int),\n",
    "        \"product_category\": [c for c, _ in product_categories],\n",
    "        \"brand\": [b for _, b in product_categories],\n",
    "        \"is_perishable\": [False, False, False, True],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4ae6825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price anchors per category for fact rows\n",
    "price_anchor = {\n",
    "    1: 199.0,  # Electronics\n",
    "    2: 350.0,  # Furniture\n",
    "    3: 40.0,   # Clothing\n",
    "    4: 5.0,    # Grocery\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Table 3: dim_customer (10 rows, labels)\n",
    "# -----------------------------\n",
    "segments = [\"Consumer\", \"Corporate\", \"Enterprise\", \"SMB\"]\n",
    "regions = [\"North\", \"South\", \"East\", \"West\", \"Central\"]\n",
    "\n",
    "dim_customer = pd.DataFrame(\n",
    "    {\n",
    "        \"customer_id\": np.arange(1, 11, dtype=int),\n",
    "        \"customer_name\": [f\"Customer {i}\" for i in range(1, 11)],\n",
    "        \"segment\": rng.choice(segments, size=10, replace=True),\n",
    "        \"region\": rng.choice(regions, size=10, replace=True),\n",
    "        \"loyalty_tier\": rng.choice([\"Bronze\", \"Silver\", \"Gold\", \"Platinum\"], size=10, replace=True),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d002ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Table 4: dim_store (50 rows, continuous)\n",
    "# -----------------------------\n",
    "cities = [\n",
    "    \"London\", \"Birmingham\", \"Manchester\", \"Leeds\", \"Glasgow\",\n",
    "    \"Liverpool\", \"Bristol\", \"Sheffield\", \"Edinburgh\", \"Cardiff\"\n",
    "]\n",
    "# Reasonable continuous fields: area (sqft), latitude, longitude, target_daily_sales\n",
    "store_area = np.clip(rng.normal(loc=20000, scale=5000, size=50), 5000, 50000)\n",
    "target_daily_sales = np.clip(rng.normal(loc=25000, scale=8000, size=50), 5000, 60000)\n",
    "\n",
    "# Rough UK lat/lon bounds for realism (not exact)\n",
    "latitudes = rng.uniform(50.0, 57.5, size=50)\n",
    "longitudes = rng.uniform(-6.0, 1.5, size=50)\n",
    "\n",
    "dim_store = pd.DataFrame(\n",
    "    {\n",
    "        \"store_id\": np.arange(1, 51, dtype=int),\n",
    "        \"store_name\": [f\"Store {i}\" for i in range(1, 51)],\n",
    "        \"city\": rng.choice(cities, size=50, replace=True),\n",
    "        \"store_area_sqft\": np.round(store_area, 0).astype(int),\n",
    "        \"latitude\": np.round(latitudes, 5),\n",
    "        \"longitude\": np.round(longitudes, 5),\n",
    "        \"target_daily_sales\": np.round(target_daily_sales, 2),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbd0206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Table 2: dim_reading (1,000 rows, continuous)\n",
    "# -----------------------------\n",
    "# Think of these as IoT sensor readings; each is referenced by the fact table.\n",
    "reading_times = random_datetimes(\n",
    "    n=1000,\n",
    "    start=\"2024-01-01 00:00:00\",\n",
    "    end=\"2025-10-24 23:59:59\",\n",
    "    rng=rng,\n",
    ")\n",
    "\n",
    "temperature_c = rng.normal(loc=20.0, scale=5.0, size=1000)         # ~20C with variation\n",
    "humidity_pct = rng.uniform(20.0, 90.0, size=1000)                  # 20% - 90%\n",
    "pressure_kpa = rng.normal(loc=101.3, scale=2.0, size=1000)         # around 101.3 kPa\n",
    "vibration_rms = np.abs(rng.normal(loc=0.5, scale=0.2, size=1000))  # non-negative\n",
    "\n",
    "dim_reading = pd.DataFrame(\n",
    "    {\n",
    "        \"reading_id\": np.arange(1, 1001, dtype=int),\n",
    "        \"reading_ts\": reading_times.sort_values().values,\n",
    "        \"temperature_c\": np.round(temperature_c, 2),\n",
    "        \"humidity_pct\": np.round(humidity_pct, 2),\n",
    "        \"pressure_kpa\": np.round(pressure_kpa, 2),\n",
    "        \"vibration_rms\": np.round(vibration_rms, 3),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c286d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Table 1: fact_sales (main fact table, 1,000 rows)\n",
    "# -----------------------------\n",
    "# Foreign keys: customer_id -> dim_customer, product_id -> dim_product,\n",
    "#               store_id -> dim_store, reading_id -> dim_reading\n",
    "# We'll create a 1:1 mapping between fact rows and reading_id (to satisfy 1000 FK values),\n",
    "# and sample other dimensions with realistic distributions.\n",
    "\n",
    "# Transaction timestamps roughly correlate with the reading timestamp plus a small jitter.\n",
    "reading_ids = np.arange(1, 1001, dtype=int)\n",
    "rng.shuffle(reading_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db9ae48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_times = dim_reading.set_index(\"reading_id\").loc[reading_ids, \"reading_ts\"].values\n",
    "jitter_seconds = rng.integers(-3600, 3600, size=1000)  # +/- 1 hour\n",
    "fact_timestamps = pd.to_datetime(base_times) + pd.to_timedelta(jitter_seconds, unit=\"s\")\n",
    "\n",
    "customer_ids = rng.integers(1, 11, size=1000)  # 1..10\n",
    "product_ids = rng.integers(1, 5, size=1000)    # 1..4\n",
    "store_ids = rng.integers(1, 51, size=1000)     # 1..50\n",
    "\n",
    "# Quantity depends weakly on product category (e.g., groceries bought in multiples)\n",
    "quantity = []\n",
    "unit_price = []\n",
    "for pid in product_ids:\n",
    "    q = int(np.clip(rng.normal(loc=2.0 if pid == 4 else 1.2, scale=0.8, size=1)[0], 1, 8))\n",
    "    anchor = price_anchor[pid]\n",
    "    # Add category-specific noise\n",
    "    price = np.round(float(np.clip(rng.normal(loc=anchor, scale=anchor * 0.15, size=1)[0], anchor*0.5, anchor*2.0)), 2)\n",
    "    quantity.append(q)\n",
    "    unit_price.append(price)\n",
    "\n",
    "quantity = np.array(quantity, dtype=int)\n",
    "unit_price = np.array(unit_price, dtype=float)\n",
    "amount = np.round(quantity * unit_price, 2)\n",
    "\n",
    "fact_sales = pd.DataFrame(\n",
    "    {\n",
    "        \"sale_id\": np.arange(1, 1001, dtype=int),\n",
    "        \"sale_ts\": fact_timestamps,\n",
    "        \"customer_id\": customer_ids,\n",
    "        \"product_id\": product_ids,\n",
    "        \"store_id\": store_ids,\n",
    "        \"reading_id\": reading_ids,  # FK to dim_reading (1:1 here)\n",
    "        \"quantity\": quantity,\n",
    "        \"unit_price\": unit_price,\n",
    "        \"amount\": amount,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6e013e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Save to CSV\n",
    "# -----------------------------\n",
    "out_dir = Path(\".\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "paths = {\n",
    "    \"fact_sales\": out_dir / \"star_schema_fact_sales.csv\",\n",
    "    \"dim_reading\": out_dir / \"star_schema_dim_reading.csv\",\n",
    "    \"dim_customer\": out_dir / \"star_schema_dim_customer.csv\",\n",
    "    \"dim_store\": out_dir / \"star_schema_dim_store.csv\",\n",
    "    \"dim_product\": out_dir / \"star_schema_dim_product.csv\",\n",
    "}\n",
    "\n",
    "fact_sales.to_csv(paths[\"fact_sales\"], index=False)\n",
    "dim_reading.to_csv(paths[\"dim_reading\"], index=False)\n",
    "dim_customer.to_csv(paths[\"dim_customer\"], index=False)\n",
    "dim_store.to_csv(paths[\"dim_store\"], index=False)\n",
    "dim_product.to_csv(paths[\"dim_product\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c492c466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fact_sales':                       dtype  non_null  n_unique\n",
       " sale_id               int64      1000      1000\n",
       " sale_ts      datetime64[ns]      1000      1000\n",
       " customer_id           int64      1000        10\n",
       " product_id            int64      1000         4\n",
       " store_id              int64      1000        50\n",
       " reading_id            int64      1000      1000\n",
       " quantity              int64      1000         5\n",
       " unit_price          float64      1000       901\n",
       " amount              float64      1000       950,\n",
       " 'dim_reading':                         dtype  non_null  n_unique\n",
       " reading_id              int64      1000      1000\n",
       " reading_ts     datetime64[ns]      1000      1000\n",
       " temperature_c         float64      1000       780\n",
       " humidity_pct          float64      1000       941\n",
       " pressure_kpa          float64      1000       560\n",
       " vibration_rms         float64      1000       559,\n",
       " 'dim_customer':                 dtype  non_null  n_unique\n",
       " customer_id     int64        10        10\n",
       " customer_name  object        10        10\n",
       " segment        object        10         4\n",
       " region         object        10         4\n",
       " loyalty_tier   object        10         4,\n",
       " 'dim_store':                       dtype  non_null  n_unique\n",
       " store_id              int64        50        50\n",
       " store_name           object        50        50\n",
       " city                 object        50        10\n",
       " store_area_sqft       int64        50        50\n",
       " latitude            float64        50        50\n",
       " longitude           float64        50        50\n",
       " target_daily_sales  float64        50        50,\n",
       " 'dim_product':                    dtype  non_null  n_unique\n",
       " product_id         int64         4         4\n",
       " product_category  object         4         4\n",
       " brand             object         4         4\n",
       " is_perishable       bool         4         2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Basic integrity checks\n",
    "# -----------------------------\n",
    "# Ensure FK coverage\n",
    "assert set(fact_sales[\"customer_id\"].unique()).issubset(set(dim_customer[\"customer_id\"]))\n",
    "assert set(fact_sales[\"product_id\"].unique()).issubset(set(dim_product[\"product_id\"]))\n",
    "assert set(fact_sales[\"store_id\"].unique()).issubset(set(dim_store[\"store_id\"]))\n",
    "assert set(fact_sales[\"reading_id\"].unique()).issubset(set(dim_reading[\"reading_id\"]))\n",
    "\n",
    "\n",
    "# Show concise schema summaries\n",
    "def df_schema(df):\n",
    "    return pd.DataFrame({\"dtype\": df.dtypes.astype(str), \"non_null\": df.notnull().sum(), \"n_unique\": df.nunique()})\n",
    "\n",
    "schemas = {\n",
    "    \"fact_sales\": df_schema(fact_sales),\n",
    "    \"dim_reading\": df_schema(dim_reading),\n",
    "    \"dim_customer\": df_schema(dim_customer),\n",
    "    \"dim_store\": df_schema(dim_store),\n",
    "    \"dim_product\": df_schema(dim_product),\n",
    "}\n",
    "\n",
    "schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97725b33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
